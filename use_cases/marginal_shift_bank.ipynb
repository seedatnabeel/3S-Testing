{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d7413eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nabeel/miniconda3/envs/3s_final_env/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "from ctgan.synthesizers.ctgan import CTGANSynthesizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from src.data_loader import load_seer_cutract_dataset\n",
    "from src.utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd087ad",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfd5d51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "seed = 0\n",
    "df = pd.read_csv(\"../data/Base.csv\")\n",
    "for col in [\n",
    "    \"payment_type\",\n",
    "    \"employment_status\",\n",
    "    \"housing_status\",\n",
    "    \"source\",\n",
    "    \"device_os\",\n",
    "]:\n",
    "    df[col] = df[col].astype(\"category\").cat.codes\n",
    "\n",
    "df.rename(columns={\"fraud_bool\": \"y\"}, inplace=True)\n",
    "\n",
    "mask = df[\"y\"] == True\n",
    "df_fraud = df[mask]\n",
    "df_no = df[~mask]\n",
    "\n",
    "n_samples = 10000\n",
    "df = pd.concat(\n",
    "    [\n",
    "        df_fraud.sample(n_samples, random_state=seed),\n",
    "        df_no.sample(n_samples, random_state=seed),\n",
    "    ]\n",
    ")\n",
    "\n",
    "df = shuffle(df, random_state=seed)\n",
    "\n",
    "X_train = df[df[\"month\"] < 6]\n",
    "X_test = df[df[\"month\"] >= 6]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3849f768",
   "metadata": {},
   "source": [
    "# Train base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c06e8627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "model_dict = {\n",
    "    \"mlp\": MLPClassifier(),\n",
    "    \"knn\": KNeighborsClassifier(),\n",
    "    \"dt\": DecisionTreeClassifier(),\n",
    "    \"rf\": RandomForestClassifier(),\n",
    "    \"gbc\": GradientBoostingClassifier(),\n",
    "}\n",
    "\n",
    "trained_model_dict = {}\n",
    "\n",
    "for model in model_dict.keys():\n",
    "    clf = model_dict[model]\n",
    "    clf.fit(X_train.drop(\"y\", axis=1), X_train[\"y\"])\n",
    "\n",
    "    trained_model_dict[model] = deepcopy(clf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eefe6e",
   "metadata": {},
   "source": [
    "# Train Generative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2ba150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_columns = [\n",
    "    \"y\",\n",
    "    \"payment_type\",\n",
    "    \"employment_status\",\n",
    "    \"housing_status\",\n",
    "    \"source\",\n",
    "    \"device_os\",\n",
    "]\n",
    "\n",
    "\n",
    "syn_model = CTGANSynthesizer(\n",
    "    embedding_dim=128,\n",
    "    generator_dim=(256, 256),\n",
    "    discriminator_dim=(256, 256),\n",
    "    generator_lr=2e-4,\n",
    "    generator_decay=1e-6,\n",
    "    discriminator_lr=2e-4,\n",
    "    discriminator_decay=1e-6,\n",
    "    batch_size=500,\n",
    "    discriminator_steps=1,\n",
    "    log_frequency=True,\n",
    "    verbose=False,\n",
    "    epochs=300,\n",
    "    pac=10,\n",
    "    cuda=True,\n",
    ")\n",
    "\n",
    "seed_everything(seed)\n",
    "syn_model.set_random_state(seed)\n",
    "syn_model.fit(train_data=X_train, discrete_columns=discrete_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511529a2",
   "metadata": {},
   "source": [
    "# Identify column of the marginal to shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54325026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import ma\n",
    "from tqdm import tqdm\n",
    "\n",
    "metric = \"session_length_in_minutes\"\n",
    "data = X_train[metric]\n",
    "cat_groups_present = False\n",
    "\n",
    "if len(np.unique(data)) < 10:\n",
    "    cat_groups = np.unique(data)\n",
    "    cat_groups_present = True\n",
    "else:\n",
    "    mean, std = np.mean(data), np.std(data)\n",
    "\n",
    "    minimum, maximum = np.min(data), np.max(data)\n",
    "\n",
    "eval_idx = np.where(X_train.columns == metric)[0][0]\n",
    "eval_idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2c756d",
   "metadata": {},
   "source": [
    "# Shift 3S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "652d3e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.shift import rejection_sample\n",
    "\n",
    "ys_mlp_all = []\n",
    "ys_knn_all = []\n",
    "ys_dt_all = []\n",
    "ys_rf_all = []\n",
    "ys_gbc_all = []\n",
    "\n",
    "cut_off = X_train[metric].quantile([0.25]).values[0]\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    ys_mlp_tmp = []\n",
    "    ys_knn_tmp = []\n",
    "    ys_dt_tmp = []\n",
    "    ys_rf_tmp = []\n",
    "    ys_gbc_tmp = []\n",
    "    n_range = 10\n",
    "    n_std = 1 * std\n",
    "\n",
    "    shift_df, _ = syn_model.sample(n=10000, shift=False)\n",
    "\n",
    "    xs = list(\n",
    "        np.arange(\n",
    "            mean - n_std, mean + n_std, ((mean + n_std) - (mean - n_std)) / n_range\n",
    "        )\n",
    "    )  #\n",
    "    for shift_mean in np.arange(\n",
    "        mean - n_std, mean + n_std, ((mean + n_std) - (mean - n_std)) / n_range\n",
    "    ):  #\n",
    "\n",
    "        if shift_mean < cut_off:\n",
    "            continue\n",
    "\n",
    "        reject_df = rejection_sample(\n",
    "            D=shift_df, mean=shift_mean, std=std / 2, feat_id=[eval_idx]\n",
    "        )\n",
    "        if len(reject_df) == 0:\n",
    "            continue\n",
    "        test_df = pd.DataFrame(reject_df, columns=X_test.columns)\n",
    "        real_tester = test_df\n",
    "        for model in model_dict.keys():\n",
    "            clf = model_dict[model]\n",
    "            y_score = clf.predict_proba(real_tester.drop(\"y\", axis=1))[:, 1]\n",
    "            y_pred = clf.predict(real_tester.drop(\"y\", axis=1))\n",
    "\n",
    "            if model == \"mlp\":\n",
    "                ys_mlp_tmp.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "            if model == \"knn\":\n",
    "                ys_knn_tmp.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "            if model == \"dt\":\n",
    "                ys_dt_tmp.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "            if model == \"rf\":\n",
    "                ys_rf_tmp.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "            if model == \"gbc\":\n",
    "                ys_gbc_tmp.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "    ys_mlp_all.append(ys_mlp_tmp)\n",
    "    ys_knn_all.append(ys_knn_tmp)\n",
    "    ys_dt_all.append(ys_dt_tmp)\n",
    "    ys_rf_all.append(ys_rf_tmp)\n",
    "    ys_gbc_all.append(ys_gbc_tmp)\n",
    "\n",
    "xs = np.array(xs)[xs > cut_off]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b028f807",
   "metadata": {},
   "source": [
    "# Rejection sample (Test/Oracle data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b6caeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_mlp = []\n",
    "yr_knn = []\n",
    "yr_dt = []\n",
    "yr_rf = []\n",
    "yr_gbc = []\n",
    "xr = list(\n",
    "    np.arange(mean - n_std, mean + n_std, ((mean + n_std) - (mean - n_std)) / n_range)\n",
    ")\n",
    "i = 0\n",
    "for shift_mean in np.arange(\n",
    "    mean - n_std, mean + n_std, ((mean + n_std) - (mean - n_std)) / n_range\n",
    "):\n",
    "\n",
    "    if shift_mean < cut_off:\n",
    "        continue\n",
    "    reject_df = rejection_sample(\n",
    "        D=X_test, mean=shift_mean, std=std / 2, feat_id=[eval_idx]\n",
    "    )\n",
    "    if len(reject_df) == 0:\n",
    "        continue\n",
    "    test_df = pd.DataFrame(reject_df, columns=X_test.columns)\n",
    "    real_tester = test_df\n",
    "    for model in model_dict.keys():\n",
    "        clf = model_dict[model]\n",
    "        y_score = clf.predict_proba(real_tester.drop(\"y\", axis=1))[:, 1]\n",
    "        y_pred = clf.predict(real_tester.drop(\"y\", axis=1))\n",
    "\n",
    "        if model == \"mlp\":\n",
    "            yr_mlp.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"knn\":\n",
    "            yr_knn.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"dt\":\n",
    "            yr_dt.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"rf\":\n",
    "            yr_rf.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"gbc\":\n",
    "            yr_gbc.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "\n",
    "xr = np.array(xr)[xr > cut_off]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d66dbc",
   "metadata": {},
   "source": [
    "# Shift RS (Source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0e2a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_mlp_val = []\n",
    "yr_knn_val = []\n",
    "yr_dt_val = []\n",
    "yr_rf_val = []\n",
    "yr_gbc_val = []\n",
    "xr = list(\n",
    "    np.arange(mean - n_std, mean + n_std, ((mean + n_std) - (mean - n_std)) / n_range)\n",
    ")\n",
    "i = 0\n",
    "for shift_mean in np.arange(\n",
    "    mean - n_std, mean + n_std, ((mean + n_std) - (mean - n_std)) / n_range\n",
    "):\n",
    "\n",
    "    if shift_mean < cut_off:\n",
    "        continue\n",
    "    reject_df = rejection_sample(\n",
    "        D=X_train, mean=shift_mean, std=std / 2, feat_id=[eval_idx]\n",
    "    )\n",
    "    if len(reject_df) == 0:\n",
    "        continue\n",
    "    test_df = pd.DataFrame(reject_df, columns=X_train.columns)\n",
    "    real_tester = test_df\n",
    "    for model in model_dict.keys():\n",
    "        clf = model_dict[model]\n",
    "        y_score = clf.predict_proba(real_tester.drop(\"y\", axis=1))[:, 1]\n",
    "        y_pred = clf.predict(real_tester.drop(\"y\", axis=1))\n",
    "\n",
    "        if model == \"mlp\":\n",
    "            yr_mlp_val.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"knn\":\n",
    "            yr_knn_val.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"dt\":\n",
    "            yr_dt_val.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"rf\":\n",
    "            yr_rf_val.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"gbc\":\n",
    "            yr_gbc_val.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "\n",
    "xr = np.array(xs)[xs > cut_off]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0efa89c",
   "metadata": {},
   "source": [
    "# Mean Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4807461",
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_mlp_ms = []\n",
    "yr_knn_ms = []\n",
    "yr_dt_ms = []\n",
    "yr_rf_ms = []\n",
    "yr_gbc_ms = []\n",
    "xr = list(\n",
    "    np.arange(mean - n_std, mean + n_std, ((mean + n_std) - (mean - n_std)) / n_range)\n",
    ")\n",
    "i = 0\n",
    "for shift_mean in np.arange(\n",
    "    mean - n_std, mean + n_std, ((mean + n_std) - (mean - n_std)) / n_range\n",
    "):\n",
    "    from copy import deepcopy\n",
    "\n",
    "    if shift_mean < cut_off:\n",
    "        continue\n",
    "    test_df = deepcopy(X_train)\n",
    "    test_df[metric] = np.random.normal(\n",
    "        loc=shift_mean, scale=std / 2, size=len(X_train[metric])\n",
    "    )\n",
    "    if len(reject_df) == 0:\n",
    "        continue\n",
    "\n",
    "    real_tester = test_df\n",
    "    for model in model_dict.keys():\n",
    "        clf = model_dict[model]\n",
    "        y_score = clf.predict_proba(real_tester.drop(\"y\", axis=1))[:, 1]\n",
    "        y_pred = clf.predict(real_tester.drop(\"y\", axis=1))\n",
    "\n",
    "        if model == \"mlp\":\n",
    "            yr_mlp_ms.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"knn\":\n",
    "            yr_knn_ms.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"dt\":\n",
    "            yr_dt_ms.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"rf\":\n",
    "            yr_rf_ms.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"gbc\":\n",
    "            yr_gbc_ms.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "\n",
    "xs = np.array(xs)[xs > cut_off]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ca1114",
   "metadata": {},
   "source": [
    "# Compare to performance on oracle/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24a0a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.where((X_train[metric] > xs[0]) & (X_train[metric] < xs[-1]))\n",
    "quantiles = X_train[metric].iloc[ids].quantile([0.25, 0.5, 0.75]).values\n",
    "q1 = xs < quantiles[0]\n",
    "q2 = (xs > quantiles[0]) & (xs < quantiles[2])\n",
    "q3 = xs > quantiles[2]\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "q1_dict = {}\n",
    "q1_dict[\"Error 3S\"] = np.mean(np.abs(np.mean(ys_rf_all, axis=0) - yr_rf)[q1])\n",
    "q1_dict[\"Error MS\"] = np.mean(np.abs(np.array(yr_rf_ms) - np.array(yr_rf))[q1])\n",
    "q1_dict[\"Error RS\"] = np.mean(np.abs(np.array(yr_rf_val) - np.array(yr_rf))[q1])\n",
    "\n",
    "q2_dict = {}\n",
    "q2_dict[\"Error 3S\"] = np.mean(np.abs(np.mean(ys_rf_all, axis=0) - yr_rf)[q2])\n",
    "q2_dict[\"Error MS\"] = np.mean(np.abs(np.array(yr_rf_ms) - np.array(yr_rf))[q2])\n",
    "q2_dict[\"Error RS\"] = np.mean(np.abs(np.array(yr_rf_val) - np.array(yr_rf))[q2])\n",
    "\n",
    "q3_dict = {}\n",
    "q3_dict[\"Error 3S\"] = np.mean(np.abs(np.mean(ys_rf_all, axis=0) - yr_rf)[q3])\n",
    "q3_dict[\"Error MS\"] = np.mean(np.abs(np.array(yr_rf_ms) - np.array(yr_rf))[q3])\n",
    "q3_dict[\"Error RS\"] = np.mean(np.abs(np.array(yr_rf_val) - np.array(yr_rf))[q3])\n",
    "\n",
    "results[\"Q1\"] = q1_dict\n",
    "results[\"Q2\"] = q2_dict\n",
    "results[\"Q3\"] = q3_dict\n",
    "\n",
    "\n",
    "threeS_err = np.abs(np.mean(ys_rf_all, axis=0) - yr_rf)\n",
    "avg_dict = {}\n",
    "avg_dict[\"Error 3S\"] = np.mean(threeS_err)\n",
    "avg_dict[\"Error MS\"] = np.mean(np.abs(np.array(yr_rf_ms) - np.array(yr_rf)))\n",
    "avg_dict[\"Error RS\"] = np.mean(np.abs(np.array(yr_rf_val) - np.array(yr_rf)))\n",
    "\n",
    "results[\"avg\"] = avg_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a1ffe4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1': {'Error 3S': 0.03650000000000009,\n",
       "  'Error MS': 0.1861331769611675,\n",
       "  'Error RS': 0.18899999999999995},\n",
       " 'Q2': {'Error 3S': 0.03600000000000003,\n",
       "  'Error MS': 0.19916575449569973,\n",
       "  'Error RS': 0.20199999999999996},\n",
       " 'Q3': {'Error 3S': 0.06787500000000005,\n",
       "  'Error MS': 0.1793619364086526,\n",
       "  'Error RS': 0.18275},\n",
       " 'avg': {'Error 3S': 0.05428571428571433,\n",
       "  'Error MS': 0.18598749022673963,\n",
       "  'Error RS': 0.1891428571428571}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = np.where((X_train[metric] > xs[0]) & (X_train[metric] < xs[-1]))\n",
    "quantiles = X_train[metric].iloc[ids].quantile([0.25, 0.5, 0.75]).values\n",
    "q1 = xs < quantiles[0]\n",
    "q2 = (xs > quantiles[0]) & (xs < quantiles[2])\n",
    "q3 = xs > quantiles[2]\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "q1_dict = {}\n",
    "q1_dict[\"Error 3S\"] = np.mean(np.abs(np.mean(ys_rf_all, axis=0) - yr_rf)[q1])\n",
    "q1_dict[\"Error MS\"] = np.mean(np.abs(np.array(yr_rf_ms) - np.array(yr_rf))[q1])\n",
    "q1_dict[\"Error RS\"] = np.mean(np.abs(np.array(yr_rf_val) - np.array(yr_rf))[q1])\n",
    "\n",
    "q2_dict = {}\n",
    "q2_dict[\"Error 3S\"] = np.mean(np.abs(np.mean(ys_rf_all, axis=0) - yr_rf)[q2])\n",
    "q2_dict[\"Error MS\"] = np.mean(np.abs(np.array(yr_rf_ms) - np.array(yr_rf))[q2])\n",
    "q2_dict[\"Error RS\"] = np.mean(np.abs(np.array(yr_rf_val) - np.array(yr_rf))[q2])\n",
    "\n",
    "q3_dict = {}\n",
    "q3_dict[\"Error 3S\"] = np.mean(np.abs(np.mean(ys_rf_all, axis=0) - yr_rf)[q3])\n",
    "q3_dict[\"Error MS\"] = np.mean(np.abs(np.array(yr_rf_ms) - np.array(yr_rf))[q3])\n",
    "q3_dict[\"Error RS\"] = np.mean(np.abs(np.array(yr_rf_val) - np.array(yr_rf))[q3])\n",
    "\n",
    "results[\"Q1\"] = q1_dict\n",
    "results[\"Q2\"] = q2_dict\n",
    "results[\"Q3\"] = q3_dict\n",
    "\n",
    "\n",
    "threeS_err = np.abs(np.mean(ys_rf_all, axis=0) - yr_rf)\n",
    "avg_dict = {}\n",
    "avg_dict[\"Error 3S\"] = np.mean(threeS_err)\n",
    "avg_dict[\"Error MS\"] = np.mean(np.abs(np.array(yr_rf_ms) - np.array(yr_rf)))\n",
    "avg_dict[\"Error RS\"] = np.mean(np.abs(np.array(yr_rf_val) - np.array(yr_rf)))\n",
    "\n",
    "results[\"avg\"] = avg_dict\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4baff7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3s_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
