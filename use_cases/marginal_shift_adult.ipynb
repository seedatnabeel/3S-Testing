{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d7413eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nabeel/miniconda3/envs/3s_final_env/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "from ctgan.synthesizers.ctgan import CTGANSynthesizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from src.data_loader import load_adult_data\n",
    "from src.utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9071281f",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfd5d51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train, X_test, y_train, y_test, X, y = load_adult_data()\n",
    "\n",
    "D_adult = X\n",
    "D_adult[\"y\"] = y\n",
    "seed = 0\n",
    "X_train, X_test = train_test_split(D_adult, test_size=0.6, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3849f768",
   "metadata": {},
   "source": [
    "# Train base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c06e8627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model_dict = {\n",
    "    \"mlp\": MLPClassifier(),\n",
    "    \"knn\": KNeighborsClassifier(),\n",
    "    \"dt\": DecisionTreeClassifier(),\n",
    "    \"rf\": RandomForestClassifier(),\n",
    "    \"gbc\": GradientBoostingClassifier(),\n",
    "}\n",
    "\n",
    "trained_model_dict = {}\n",
    "\n",
    "for model in model_dict.keys():\n",
    "    clf = model_dict[model]\n",
    "    clf.fit(X_train.drop(\"y\", axis=1), X_train[\"y\"])\n",
    "\n",
    "    trained_model_dict[model] = deepcopy(clf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a25105a",
   "metadata": {},
   "source": [
    "# Train Generative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2ba150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_columns = [\n",
    "    \"education-num\",\n",
    "    \"marital-status\",\n",
    "    \"employment_type\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"country\",\n",
    "]\n",
    "\n",
    "syn_model = CTGANSynthesizer(\n",
    "    embedding_dim=128,\n",
    "    generator_dim=(256, 256),\n",
    "    discriminator_dim=(256, 256),\n",
    "    generator_lr=2e-4,\n",
    "    generator_decay=1e-6,\n",
    "    discriminator_lr=2e-4,\n",
    "    discriminator_decay=1e-6,\n",
    "    batch_size=500,\n",
    "    discriminator_steps=1,\n",
    "    log_frequency=True,\n",
    "    verbose=False,\n",
    "    epochs=300,\n",
    "    pac=10,\n",
    "    cuda=True,\n",
    ")\n",
    "\n",
    "seed_everything(seed)\n",
    "syn_model.set_random_state(seed)\n",
    "syn_model.fit(train_data=X_train, discrete_columns=discrete_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab4b576",
   "metadata": {},
   "source": [
    "# Identify column of the marginal to shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54325026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "metric = \"age\"\n",
    "data = X_train[metric]\n",
    "cat_groups_present = False\n",
    "\n",
    "if len(np.unique(data)) < 10:\n",
    "    cat_groups = np.unique(data)\n",
    "    cat_groups_present = True\n",
    "else:\n",
    "    mean, std = np.mean(data), np.std(data)\n",
    "\n",
    "    minimum, maximum = np.min(data), np.max(data)\n",
    "\n",
    "eval_idx = np.where(X_train.columns == metric)[0][0]\n",
    "eval_idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c714f8",
   "metadata": {},
   "source": [
    "# Shift 3S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "652d3e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.shift import rejection_sample\n",
    "\n",
    "ys_mlp_all = []\n",
    "ys_knn_all = []\n",
    "ys_dt_all = []\n",
    "ys_rf_all = []\n",
    "ys_gbc_all = []\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    ys_mlp_tmp = []\n",
    "    ys_knn_tmp = []\n",
    "    ys_dt_tmp = []\n",
    "    ys_rf_tmp = []\n",
    "    ys_gbc_tmp = []\n",
    "    n_range = 10\n",
    "    n_std = 1 * std\n",
    "\n",
    "    shift_df, _ = syn_model.sample(n=10000, shift=False)\n",
    "\n",
    "    xs = list(\n",
    "        np.arange(\n",
    "            mean - n_std, mean + n_std, ((mean + n_std) - (mean - n_std)) / n_range\n",
    "        )\n",
    "    )  \n",
    "    for shift_mean in np.arange(\n",
    "        mean - n_std, mean + n_std, ((mean + n_std) - (mean - n_std)) / n_range\n",
    "    ): \n",
    "\n",
    "        reject_df = rejection_sample(\n",
    "            D=shift_df, mean=shift_mean, std=std / 2, feat_id=[0]\n",
    "        )\n",
    "        if len(reject_df) == 0:\n",
    "            continue\n",
    "        test_df = pd.DataFrame(reject_df, columns=X_test.columns)\n",
    "        real_tester = test_df\n",
    "        for model in model_dict.keys():\n",
    "            clf = model_dict[model]\n",
    "            y_score = clf.predict_proba(real_tester.drop(\"y\", axis=1))[:, 1]\n",
    "            y_pred = clf.predict(real_tester.drop(\"y\", axis=1))\n",
    "\n",
    "            if model == \"mlp\":\n",
    "                ys_mlp_tmp.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "            if model == \"knn\":\n",
    "                ys_knn_tmp.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "            if model == \"dt\":\n",
    "                ys_dt_tmp.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "            if model == \"rf\":\n",
    "                ys_rf_tmp.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "            if model == \"gbc\":\n",
    "                ys_gbc_tmp.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "    ys_mlp_all.append(ys_mlp_tmp)\n",
    "    ys_knn_all.append(ys_knn_tmp)\n",
    "    ys_dt_all.append(ys_dt_tmp)\n",
    "    ys_rf_all.append(ys_rf_tmp)\n",
    "    ys_gbc_all.append(ys_gbc_tmp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febcf736",
   "metadata": {},
   "source": [
    "# Rejection sample (Test/Oracle data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b6caeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_mlp = []\n",
    "yr_knn = []\n",
    "yr_dt = []\n",
    "yr_rf = []\n",
    "yr_gbc = []\n",
    "xr = list(\n",
    "    np.arange(mean - n_std, mean + n_std, ((mean + n_std) - (mean - n_std)) / n_range)\n",
    ")  \n",
    "i = 0\n",
    "for shift_mean in np.arange(\n",
    "    mean - n_std, mean + n_std, ((mean + n_std) - (mean - n_std)) / n_range\n",
    "):  \n",
    "\n",
    "    reject_df = rejection_sample(D=X_test, mean=shift_mean, std=std / 2, feat_id=[0])\n",
    "    if len(reject_df) == 0:\n",
    "        continue\n",
    "    test_df = pd.DataFrame(reject_df, columns=X_test.columns)\n",
    "    real_tester = test_df\n",
    "    for model in model_dict.keys():\n",
    "        clf = model_dict[model]\n",
    "        y_score = clf.predict_proba(real_tester.drop(\"y\", axis=1))[:, 1]\n",
    "        y_pred = clf.predict(real_tester.drop(\"y\", axis=1))\n",
    "\n",
    "        if model == \"mlp\":\n",
    "            yr_mlp.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"knn\":\n",
    "            yr_knn.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"dt\":\n",
    "            yr_dt.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"rf\":\n",
    "            yr_rf.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"gbc\":\n",
    "            yr_gbc.append(accuracy_score(real_tester[\"y\"], y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4334e6da",
   "metadata": {},
   "source": [
    "# Shift RS (Source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0e2a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_mlp_val = []\n",
    "yr_knn_val = []\n",
    "yr_dt_val = []\n",
    "yr_rf_val = []\n",
    "yr_gbc_val = []\n",
    "xr = list(\n",
    "    np.arange(mean - n_std, mean + n_std, ((mean + n_std) - (mean - n_std)) / n_range)\n",
    ")  \n",
    "i = 0\n",
    "for shift_mean in np.arange(\n",
    "    mean - n_std, mean + n_std, ((mean + n_std) - (mean - n_std)) / n_range\n",
    "): \n",
    "    reject_df = rejection_sample(D=X_train, mean=shift_mean, std=std / 2, feat_id=[0])\n",
    "    if len(reject_df) == 0:\n",
    "        continue\n",
    "    test_df = pd.DataFrame(reject_df, columns=X_train.columns)\n",
    "    real_tester = test_df\n",
    "    for model in model_dict.keys():\n",
    "        clf = model_dict[model]\n",
    "        y_score = clf.predict_proba(real_tester.drop(\"y\", axis=1))[:, 1]\n",
    "        y_pred = clf.predict(real_tester.drop(\"y\", axis=1))\n",
    "\n",
    "        if model == \"mlp\":\n",
    "            yr_mlp_val.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"knn\":\n",
    "            yr_knn_val.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"dt\":\n",
    "            yr_dt_val.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"rf\":\n",
    "            yr_rf_val.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"gbc\":\n",
    "            yr_gbc_val.append(accuracy_score(real_tester[\"y\"], y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440b6057",
   "metadata": {},
   "source": [
    "# Mean Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4807461",
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_mlp_ms = []\n",
    "yr_knn_ms = []\n",
    "yr_dt_ms = []\n",
    "yr_rf_ms = []\n",
    "yr_gbc_ms = []\n",
    "xr = list(\n",
    "    np.arange(mean - n_std, mean + n_std, ((mean + n_std) - (mean - n_std)) / n_range)\n",
    ")  \n",
    "i = 0\n",
    "for shift_mean in np.arange(\n",
    "    mean - n_std, mean + n_std, ((mean + n_std) - (mean - n_std)) / n_range\n",
    "):  \n",
    "    from copy import deepcopy\n",
    "\n",
    "    test_df = deepcopy(X_train)\n",
    "    test_df[metric] = np.random.normal(\n",
    "        loc=shift_mean, scale=std, size=len(X_train[metric])\n",
    "    )\n",
    "\n",
    "    if len(reject_df) == 0:\n",
    "        continue\n",
    "  \n",
    "    real_tester = test_df\n",
    "    for model in model_dict.keys():\n",
    "        clf = model_dict[model]\n",
    "        y_score = clf.predict_proba(real_tester.drop(\"y\", axis=1))[:, 1]\n",
    "        y_pred = clf.predict(real_tester.drop(\"y\", axis=1))\n",
    "\n",
    "        if model == \"mlp\":\n",
    "            yr_mlp_ms.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"knn\":\n",
    "            yr_knn_ms.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"dt\":\n",
    "            yr_dt_ms.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"rf\":\n",
    "            yr_rf_ms.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"gbc\":\n",
    "            yr_gbc_ms.append(accuracy_score(real_tester[\"y\"], y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63380be9",
   "metadata": {},
   "source": [
    "# Compare to performance on oracle/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff33adb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1': {'Error 3S': 0.022166666666666706,\n",
       "  'Error MS': 0.05171220159151194,\n",
       "  'Error RS': 0.10466666666666664},\n",
       " 'Q2': {'Error 3S': 0.018625000000000058,\n",
       "  'Error MS': 0.05631598143236072,\n",
       "  'Error RS': 0.17874999999999994},\n",
       " 'Q3': {'Error 3S': 0.03900000000000007,\n",
       "  'Error MS': 0.06985256410256409,\n",
       "  'Error RS': 0.18633333333333332},\n",
       " 'avg': {'Error 3S': 0.025800000000000056,\n",
       "  'Error MS': 0.0589958222811671,\n",
       "  'Error RS': 0.15879999999999997}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = np.where((X_train[metric] > xs[0]) & (X_train[metric] < xs[-1]))\n",
    "quantiles = X_train[metric].iloc[ids].quantile([0.25, 0.5, 0.75]).values\n",
    "q1 = xs < quantiles[0]\n",
    "q2 = (xs > quantiles[0]) & (xs < quantiles[2])\n",
    "q3 = xs > quantiles[2]\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "q1_dict = {}\n",
    "q1_dict[\"Error 3S\"] = np.mean(np.abs(np.mean(ys_rf_all, axis=0) - yr_rf)[q1])\n",
    "q1_dict[\"Error MS\"] = np.mean(np.abs(np.array(yr_rf_ms) - np.array(yr_rf))[q1])\n",
    "q1_dict[\"Error RS\"] = np.mean(np.abs(np.array(yr_rf_val) - np.array(yr_rf))[q1])\n",
    "\n",
    "q2_dict = {}\n",
    "q2_dict[\"Error 3S\"] = np.mean(np.abs(np.mean(ys_rf_all, axis=0) - yr_rf)[q2])\n",
    "q2_dict[\"Error MS\"] = np.mean(np.abs(np.array(yr_rf_ms) - np.array(yr_rf))[q2])\n",
    "q2_dict[\"Error RS\"] = np.mean(np.abs(np.array(yr_rf_val) - np.array(yr_rf))[q2])\n",
    "\n",
    "q3_dict = {}\n",
    "q3_dict[\"Error 3S\"] = np.mean(np.abs(np.mean(ys_rf_all, axis=0) - yr_rf)[q3])\n",
    "q3_dict[\"Error MS\"] = np.mean(np.abs(np.array(yr_rf_ms) - np.array(yr_rf))[q3])\n",
    "q3_dict[\"Error RS\"] = np.mean(np.abs(np.array(yr_rf_val) - np.array(yr_rf))[q3])\n",
    "\n",
    "results[\"Q1\"] = q1_dict\n",
    "results[\"Q2\"] = q2_dict\n",
    "results[\"Q3\"] = q3_dict\n",
    "\n",
    "\n",
    "threeS_err = np.abs(np.mean(ys_rf_all, axis=0) - yr_rf)\n",
    "avg_dict = {}\n",
    "avg_dict[\"Error 3S\"] = np.mean(threeS_err)\n",
    "avg_dict[\"Error MS\"] = np.mean(np.abs(np.array(yr_rf_ms) - np.array(yr_rf)))\n",
    "avg_dict[\"Error RS\"] = np.mean(np.abs(np.array(yr_rf_val) - np.array(yr_rf)))\n",
    "\n",
    "results[\"avg\"] = avg_dict\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c74c8083",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.where((X_train[metric] > xs[0]) & (X_train[metric] < xs[-1]))\n",
    "quantiles = X_train[metric].iloc[ids].quantile([0.25, 0.5, 0.75]).values\n",
    "q1 = xs < quantiles[0]\n",
    "q2 = (xs > quantiles[0]) & (xs < quantiles[2])\n",
    "q3 = xs > quantiles[2]\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "q1_dict = {}\n",
    "q1_dict[\"Error 3S\"] = np.mean(np.abs(np.mean(ys_rf_all, axis=0) - yr_rf)[q1])\n",
    "q1_dict[\"Error MS\"] = np.mean(np.abs(np.array(yr_rf_ms) - np.array(yr_rf))[q1])\n",
    "q1_dict[\"Error RS\"] = np.mean(np.abs(np.array(yr_rf_val) - np.array(yr_rf))[q1])\n",
    "\n",
    "q2_dict = {}\n",
    "q2_dict[\"Error 3S\"] = np.mean(np.abs(np.mean(ys_rf_all, axis=0) - yr_rf)[q2])\n",
    "q2_dict[\"Error MS\"] = np.mean(np.abs(np.array(yr_rf_ms) - np.array(yr_rf))[q2])\n",
    "q2_dict[\"Error RS\"] = np.mean(np.abs(np.array(yr_rf_val) - np.array(yr_rf))[q2])\n",
    "\n",
    "q3_dict = {}\n",
    "q3_dict[\"Error 3S\"] = np.mean(np.abs(np.mean(ys_rf_all, axis=0) - yr_rf)[q3])\n",
    "q3_dict[\"Error MS\"] = np.mean(np.abs(np.array(yr_rf_ms) - np.array(yr_rf))[q3])\n",
    "q3_dict[\"Error RS\"] = np.mean(np.abs(np.array(yr_rf_val) - np.array(yr_rf))[q3])\n",
    "\n",
    "results[\"Q1\"] = q1_dict\n",
    "results[\"Q2\"] = q2_dict\n",
    "results[\"Q3\"] = q3_dict\n",
    "\n",
    "\n",
    "threeS_err = np.abs(np.mean(ys_rf_all, axis=0) - yr_rf)\n",
    "avg_dict = {}\n",
    "avg_dict[\"Error 3S\"] = np.mean(threeS_err)\n",
    "avg_dict[\"Error MS\"] = np.mean(np.abs(np.array(yr_rf_ms) - np.array(yr_rf)))\n",
    "avg_dict[\"Error RS\"] = np.mean(np.abs(np.array(yr_rf_val) - np.array(yr_rf)))\n",
    "\n",
    "results[\"avg\"] = avg_dict\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3s_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
