{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d7413eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ctgan.synthesizers.ctgan import CTGANSynthesizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from src.data_loader import load_seer_cutract_dataset\n",
    "from src.utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8ff8ac",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfd5d51e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12000, 7), (8000, 7))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 42\n",
    "X_seer, y_seer = load_seer_cutract_dataset(name=\"seer\", seed=0)\n",
    "\n",
    "D_seer = X_seer\n",
    "D_seer[\"y\"] = y_seer\n",
    "\n",
    "\n",
    "X_train, X_test = train_test_split(D_seer, test_size=0.4, random_state=seed)\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3849f768",
   "metadata": {},
   "source": [
    "# Train base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c06e8627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "model_dict = {\n",
    "    \"mlp\": MLPClassifier(),\n",
    "    \"knn\": KNeighborsClassifier(),\n",
    "    \"dt\": DecisionTreeClassifier(),\n",
    "    \"rf\": RandomForestClassifier(),\n",
    "    \"gbc\": GradientBoostingClassifier(),\n",
    "}\n",
    "\n",
    "trained_model_dict = {}\n",
    "\n",
    "for model in model_dict.keys():\n",
    "    clf = model_dict[model]\n",
    "    clf.fit(X_train.drop(\"y\", axis=1), X_train[\"y\"])\n",
    "\n",
    "    trained_model_dict[model] = deepcopy(clf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2151c923",
   "metadata": {},
   "source": [
    "# Train Generative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2ba150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "discrete_columns = [\n",
    "    \"age\",\n",
    "    \"comorbidities\",\n",
    "    \"treatment\",\n",
    "    \"grade\",\n",
    "    \"stage\",\n",
    "]\n",
    "\n",
    "syn_model = CTGANSynthesizer(\n",
    "    embedding_dim=128,\n",
    "    generator_dim=(256, 256),\n",
    "    discriminator_dim=(256, 256),\n",
    "    generator_lr=2e-4,\n",
    "    generator_decay=1e-6,\n",
    "    discriminator_lr=2e-4,\n",
    "    discriminator_decay=1e-6,\n",
    "    batch_size=500,\n",
    "    discriminator_steps=1,\n",
    "    log_frequency=True,\n",
    "    verbose=False,\n",
    "    epochs=300,\n",
    "    pac=10,\n",
    "    cuda=True,\n",
    ")\n",
    "\n",
    "seed_everything(seed)\n",
    "syn_model.set_random_state(seed)\n",
    "syn_model.fit(train_data=X_train, discrete_columns=discrete_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d189ab",
   "metadata": {},
   "source": [
    "# Identify column of the marginal to shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54325026",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"psa\"\n",
    "data = X_train[metric]\n",
    "cat_groups_present = False\n",
    "\n",
    "if len(np.unique(data)) < 10:\n",
    "    cat_groups = np.unique(data)\n",
    "    cat_groups_present = True\n",
    "else:\n",
    "    mean, std = np.mean(data), np.std(data)\n",
    "\n",
    "    minimum, maximum = np.min(data), np.max(data)\n",
    "\n",
    "eval_idx = np.where(X_train.columns == metric)[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ff5ed4",
   "metadata": {},
   "source": [
    "# Shift 3S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "652d3e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.shift import rejection_sample\n",
    "\n",
    "ys_mlp_all = []\n",
    "ys_knn_all = []\n",
    "ys_dt_all = []\n",
    "ys_rf_all = []\n",
    "ys_gbc_all = []\n",
    "\n",
    "cut_off = X_train[metric].quantile([0.25]).values[0]\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    ys_mlp_tmp = []\n",
    "    ys_knn_tmp = []\n",
    "    ys_dt_tmp = []\n",
    "    ys_rf_tmp = []\n",
    "    ys_gbc_tmp = []\n",
    "    n_range = 10\n",
    "    n_std = 1 * std\n",
    "\n",
    "    shift_df, _ = syn_model.sample(n=10000, shift=False)\n",
    "\n",
    "    xs = list(\n",
    "        np.arange(\n",
    "            mean - n_std, mean + n_std, ((mean + n_std) - (mean - n_std)) / n_range\n",
    "        )\n",
    "    )  # list(np.arange(minimum+std/2, maximum-std/2, ((maximum-std/2)-(minimum+std/2))/n_range))\n",
    "    for shift_mean in np.arange(\n",
    "        mean - n_std, mean + n_std, ((mean + n_std) - (mean - n_std)) / n_range\n",
    "    ):  # np.arange(minimum+std/2, maximum-std/2, ((maximum-std/2)-(minimum+std/2))/n_range):\n",
    "\n",
    "        if shift_mean < cut_off:\n",
    "            continue\n",
    "\n",
    "        reject_df = rejection_sample(\n",
    "            D=shift_df, mean=shift_mean, std=std / 2, feat_id=[eval_idx]\n",
    "        )\n",
    "        if len(reject_df) == 0:\n",
    "            continue\n",
    "        test_df = pd.DataFrame(reject_df, columns=X_test.columns)\n",
    "        real_tester = test_df\n",
    "        for model in model_dict.keys():\n",
    "            clf = model_dict[model]\n",
    "            y_score = clf.predict_proba(real_tester.drop(\"y\", axis=1))[:, 1]\n",
    "            y_pred = clf.predict(real_tester.drop(\"y\", axis=1))\n",
    "\n",
    "            if model == \"mlp\":\n",
    "                ys_mlp_tmp.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "            if model == \"knn\":\n",
    "                ys_knn_tmp.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "            if model == \"dt\":\n",
    "                ys_dt_tmp.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "            if model == \"rf\":\n",
    "                ys_rf_tmp.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "            if model == \"gbc\":\n",
    "                ys_gbc_tmp.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "    ys_mlp_all.append(ys_mlp_tmp)\n",
    "    ys_knn_all.append(ys_knn_tmp)\n",
    "    ys_dt_all.append(ys_dt_tmp)\n",
    "    ys_rf_all.append(ys_rf_tmp)\n",
    "    ys_gbc_all.append(ys_gbc_tmp)\n",
    "\n",
    "xs = np.array(xs)[xs > cut_off]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5970b837",
   "metadata": {},
   "source": [
    "# Rejection sample (Test/Oracle data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b6caeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_mlp = []\n",
    "yr_knn = []\n",
    "yr_dt = []\n",
    "yr_rf = []\n",
    "yr_gbc = []\n",
    "xr = list(\n",
    "    np.arange(mean - n_std, mean + n_std, ((mean + n_std) - (mean - n_std)) / n_range)\n",
    ")  # list(np.arange(minimum+std, maximum-std, ((maximum-std)-(minimum+std))/5))\n",
    "i = 0\n",
    "for shift_mean in np.arange(\n",
    "    mean - n_std, mean + n_std, ((mean + n_std) - (mean - n_std)) / n_range\n",
    "):  # np.arange(minimum+std, maximum-std, ((maximum-std)-(minimum+std))/5):\n",
    "\n",
    "    if shift_mean < cut_off:\n",
    "        continue\n",
    "    reject_df = rejection_sample(\n",
    "        D=X_test, mean=shift_mean, std=std / 2, feat_id=[eval_idx]\n",
    "    )\n",
    "    if len(reject_df) == 0:\n",
    "        continue\n",
    "    test_df = pd.DataFrame(reject_df, columns=X_test.columns)\n",
    "    real_tester = test_df\n",
    "    for model in model_dict.keys():\n",
    "        clf = model_dict[model]\n",
    "        y_score = clf.predict_proba(real_tester.drop(\"y\", axis=1))[:, 1]\n",
    "        y_pred = clf.predict(real_tester.drop(\"y\", axis=1))\n",
    "\n",
    "        if model == \"mlp\":\n",
    "            yr_mlp.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"knn\":\n",
    "            yr_knn.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"dt\":\n",
    "            yr_dt.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"rf\":\n",
    "            yr_rf.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"gbc\":\n",
    "            yr_gbc.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "\n",
    "xr = np.array(xr)[xr > cut_off]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9156833",
   "metadata": {},
   "source": [
    "# Shift RS (Source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0e2a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_mlp_val = []\n",
    "yr_knn_val = []\n",
    "yr_dt_val = []\n",
    "yr_rf_val = []\n",
    "yr_gbc_val = []\n",
    "xr = list(\n",
    "    np.arange(mean - n_std, mean + n_std, ((mean + n_std) - (mean - n_std)) / n_range)\n",
    ")  # list(np.arange(minimum+std, maximum-std, ((maximum-std)-(minimum+std))/5))\n",
    "i = 0\n",
    "for shift_mean in np.arange(\n",
    "    mean - n_std, mean + n_std, ((mean + n_std) - (mean - n_std)) / n_range\n",
    "):  # np.arange(minimum+std, maximum-std, ((maximum-std)-(minimum+std))/5):\n",
    "    if shift_mean < cut_off:\n",
    "        continue\n",
    "    reject_df = rejection_sample(\n",
    "        D=X_train, mean=shift_mean, std=std / 2, feat_id=[eval_idx]\n",
    "    )\n",
    "    if len(reject_df) == 0:\n",
    "        continue\n",
    "    test_df = pd.DataFrame(reject_df, columns=X_train.columns)\n",
    "    real_tester = test_df\n",
    "    for model in model_dict.keys():\n",
    "        clf = model_dict[model]\n",
    "        y_score = clf.predict_proba(real_tester.drop(\"y\", axis=1))[:, 1]\n",
    "        y_pred = clf.predict(real_tester.drop(\"y\", axis=1))\n",
    "\n",
    "        if model == \"mlp\":\n",
    "            yr_mlp_val.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"knn\":\n",
    "            yr_knn_val.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"dt\":\n",
    "            yr_dt_val.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"rf\":\n",
    "            yr_rf_val.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"gbc\":\n",
    "            yr_gbc_val.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "\n",
    "xr = np.array(xs)[xs > cut_off]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe94cb2c",
   "metadata": {},
   "source": [
    "# Mean Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4807461",
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_mlp_ms = []\n",
    "yr_knn_ms = []\n",
    "yr_dt_ms = []\n",
    "yr_rf_ms = []\n",
    "yr_gbc_ms = []\n",
    "xr = list(\n",
    "    np.arange(mean - n_std, mean + n_std, ((mean + n_std) - (mean - n_std)) / n_range)\n",
    ")\n",
    "i = 0\n",
    "for shift_mean in np.arange(\n",
    "    mean - n_std, mean + n_std, ((mean + n_std) - (mean - n_std)) / n_range\n",
    "):\n",
    "    from copy import deepcopy\n",
    "\n",
    "    if shift_mean < cut_off:\n",
    "        continue\n",
    "    test_df = deepcopy(X_train)\n",
    "    test_df[metric] = np.random.normal(\n",
    "        loc=shift_mean, scale=std / 2, size=len(X_train[metric])\n",
    "    )\n",
    "    if len(reject_df) == 0:\n",
    "        continue\n",
    "\n",
    "    real_tester = test_df\n",
    "    for model in model_dict.keys():\n",
    "        clf = model_dict[model]\n",
    "        y_score = clf.predict_proba(real_tester.drop(\"y\", axis=1))[:, 1]\n",
    "        y_pred = clf.predict(real_tester.drop(\"y\", axis=1))\n",
    "\n",
    "        if model == \"mlp\":\n",
    "            yr_mlp_ms.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"knn\":\n",
    "            yr_knn_ms.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"dt\":\n",
    "            yr_dt_ms.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"rf\":\n",
    "            yr_rf_ms.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "        if model == \"gbc\":\n",
    "            yr_gbc_ms.append(accuracy_score(real_tester[\"y\"], y_pred))\n",
    "\n",
    "\n",
    "xs = np.array(xs)[xs > cut_off]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314415c6",
   "metadata": {},
   "source": [
    "# Compare to performance on oracle/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1581e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1': {'Error 3S': 0.05566666666666664,\n",
       "  'Error MS': 0.026000000000000023,\n",
       "  'Error RS': 0.20299999999999996},\n",
       " 'Q2': {'Error 3S': 0.031166666666666787,\n",
       "  'Error MS': 0.03879166666666667,\n",
       "  'Error RS': 0.2345},\n",
       " 'Q3': {'Error 3S': 0.020333333333333294,\n",
       "  'Error MS': 0.03248333333333333,\n",
       "  'Error RS': 0.18619999999999998},\n",
       " 'avg': {'Error 3S': 0.027458333333333335,\n",
       "  'Error MS': 0.03325,\n",
       "  'Error RS': 0.20037499999999997}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = np.where((X_train[metric] > xs[0]) & (X_train[metric] < xs[-1]))\n",
    "quantiles = X_train[metric].iloc[ids].quantile([0.25, 0.5, 0.75]).values\n",
    "q1 = xs < quantiles[0]\n",
    "q2 = (xs > quantiles[0]) & (xs < quantiles[2])\n",
    "q3 = xs > quantiles[2]\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "q1_dict = {}\n",
    "q1_dict[\"Error 3S\"] = np.mean(np.abs(np.mean(ys_rf_all, axis=0) - yr_rf)[q1])\n",
    "q1_dict[\"Error MS\"] = np.mean(np.abs(np.array(yr_rf_ms) - np.array(yr_rf))[q1])\n",
    "q1_dict[\"Error RS\"] = np.mean(np.abs(np.array(yr_rf_val) - np.array(yr_rf))[q1])\n",
    "\n",
    "q2_dict = {}\n",
    "q2_dict[\"Error 3S\"] = np.mean(np.abs(np.mean(ys_rf_all, axis=0) - yr_rf)[q2])\n",
    "q2_dict[\"Error MS\"] = np.mean(np.abs(np.array(yr_rf_ms) - np.array(yr_rf))[q2])\n",
    "q2_dict[\"Error RS\"] = np.mean(np.abs(np.array(yr_rf_val) - np.array(yr_rf))[q2])\n",
    "\n",
    "q3_dict = {}\n",
    "q3_dict[\"Error 3S\"] = np.mean(np.abs(np.mean(ys_rf_all, axis=0) - yr_rf)[q3])\n",
    "q3_dict[\"Error MS\"] = np.mean(np.abs(np.array(yr_rf_ms) - np.array(yr_rf))[q3])\n",
    "q3_dict[\"Error RS\"] = np.mean(np.abs(np.array(yr_rf_val) - np.array(yr_rf))[q3])\n",
    "\n",
    "results[\"Q1\"] = q1_dict\n",
    "results[\"Q2\"] = q2_dict\n",
    "results[\"Q3\"] = q3_dict\n",
    "\n",
    "\n",
    "threeS_err = np.abs(np.mean(ys_rf_all, axis=0) - yr_rf)\n",
    "avg_dict = {}\n",
    "avg_dict[\"Error 3S\"] = np.mean(threeS_err)\n",
    "avg_dict[\"Error MS\"] = np.mean(np.abs(np.array(yr_rf_ms) - np.array(yr_rf)))\n",
    "avg_dict[\"Error RS\"] = np.mean(np.abs(np.array(yr_rf_val) - np.array(yr_rf)))\n",
    "\n",
    "results[\"avg\"] = avg_dict\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7d92f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.where((X_train[metric] > xs[0]) & (X_train[metric] < xs[-1]))\n",
    "quantiles = X_train[metric].iloc[ids].quantile([0.25, 0.5, 0.75]).values\n",
    "q1 = xs < quantiles[0]\n",
    "q2 = (xs > quantiles[0]) & (xs < quantiles[2])\n",
    "q3 = xs > quantiles[2]\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "q1_dict = {}\n",
    "q1_dict[\"Error 3S\"] = np.mean(np.abs(np.mean(ys_rf_all, axis=0) - yr_rf)[q1])\n",
    "q1_dict[\"Error MS\"] = np.mean(np.abs(np.array(yr_rf_ms) - np.array(yr_rf))[q1])\n",
    "q1_dict[\"Error RS\"] = np.mean(np.abs(np.array(yr_rf_val) - np.array(yr_rf))[q1])\n",
    "\n",
    "q2_dict = {}\n",
    "q2_dict[\"Error 3S\"] = np.mean(np.abs(np.mean(ys_rf_all, axis=0) - yr_rf)[q2])\n",
    "q2_dict[\"Error MS\"] = np.mean(np.abs(np.array(yr_rf_ms) - np.array(yr_rf))[q2])\n",
    "q2_dict[\"Error RS\"] = np.mean(np.abs(np.array(yr_rf_val) - np.array(yr_rf))[q2])\n",
    "\n",
    "q3_dict = {}\n",
    "q3_dict[\"Error 3S\"] = np.mean(np.abs(np.mean(ys_rf_all, axis=0) - yr_rf)[q3])\n",
    "q3_dict[\"Error MS\"] = np.mean(np.abs(np.array(yr_rf_ms) - np.array(yr_rf))[q3])\n",
    "q3_dict[\"Error RS\"] = np.mean(np.abs(np.array(yr_rf_val) - np.array(yr_rf))[q3])\n",
    "\n",
    "results[\"Q1\"] = q1_dict\n",
    "results[\"Q2\"] = q2_dict\n",
    "results[\"Q3\"] = q3_dict\n",
    "\n",
    "\n",
    "threeS_err = np.abs(np.mean(ys_rf_all, axis=0) - yr_rf)\n",
    "avg_dict = {}\n",
    "avg_dict[\"Error 3S\"] = np.mean(threeS_err)\n",
    "avg_dict[\"Error MS\"] = np.mean(np.abs(np.array(yr_rf_ms) - np.array(yr_rf)))\n",
    "avg_dict[\"Error RS\"] = np.mean(np.abs(np.array(yr_rf_val) - np.array(yr_rf)))\n",
    "\n",
    "results[\"avg\"] = avg_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8018aea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_3s_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
